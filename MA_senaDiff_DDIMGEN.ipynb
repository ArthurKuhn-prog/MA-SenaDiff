{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthurKuhn-prog/MA-SenaDiff/blob/main/MA_senaDiff_DDIMGEN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAuzxwsY35Ww",
        "outputId": "f0e7ae7c-2855-4711-a428-aa052fc63786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "##importing all the libraries needed\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "#importing google Drive to use my own Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDi5H8rmi5Ki"
      },
      "outputs": [],
      "source": [
        "#Setting up the hyperparameters and variables\n",
        "\n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "total_timesteps = 1000\n",
        "norm_groups = 8\n",
        "learning_rate = 2e-4\n",
        "\n",
        "img_height = 64\n",
        "img_width = 64\n",
        "img_channels = 3\n",
        "clip_min = -1.0\n",
        "clip_max = 1.0\n",
        "\n",
        "first_conv_channels = 64\n",
        "channel_multiplier = [1, 2, 4, 8]\n",
        "widths = [first_conv_channels * mult for mult in channel_multiplier]\n",
        "has_attention = [False, False, True, True]\n",
        "num_res_blocks = 2\n",
        "\n",
        "dataset_name = \"oxford_flowers102\"\n",
        "splits = [\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j-nIJYPi8vm",
        "outputId": "0fc291e9-0a93-4d14-e370-e8701655beef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14109 files belonging to 1 classes.\n",
            "Using 2821 files for validation.\n"
          ]
        }
      ],
      "source": [
        "#Importing the dataset from my GDrive\n",
        "\n",
        "ds = keras.utils.image_dataset_from_directory(\n",
        "  '/content/drive/MyDrive/1.MelodiaAtomizacji/senaSet/',\n",
        "  label_mode=None,\n",
        "  batch_size = None,\n",
        "  image_size=(64,64),\n",
        "  shuffle=True,\n",
        "  validation_split=0.2,\n",
        "  subset='validation',\n",
        "  seed=8111994, #Seed is needed for validation_split\n",
        ")\n",
        "\n",
        "#(ds,) = tfds.load(dataset_name, split=splits, with_info=False, shuffle_files=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLyBra7Si-Rc"
      },
      "outputs": [],
      "source": [
        "#Let's start working on the DS\n",
        "\n",
        "#Augmenting the DS with a few flips\n",
        "def augment(img):\n",
        "    return tf.image.random_flip_left_right(img)\n",
        "\n",
        "#Resizing the image and rescale its values from [-1.0, 1.0]\n",
        "#img is the image tensor\n",
        "#size is the desired size of the image\n",
        "def resize_and_rescale(img, size):\n",
        "    height = tf.shape(img)[0]\n",
        "    width = tf.shape(img)[1]\n",
        "    crop_size = tf.minimum(height, width)\n",
        "\n",
        "    imf = tf.image.crop_to_bounding_box(\n",
        "        img,\n",
        "        (height - crop_size) // 2,\n",
        "        (width - crop_size) // 2,\n",
        "        crop_size,\n",
        "        crop_size,\n",
        "    )\n",
        "\n",
        "    #Resize the image\n",
        "    img = tf.cast(img, dtype=tf.float32)\n",
        "    img = tf.image.resize(img, size=size, antialias=True)\n",
        "\n",
        "    #Rescale the pixel values\n",
        "    img = img / 127.5 - 1.0\n",
        "    img = tf.clip_by_value(img, clip_min, clip_max)\n",
        "    return img\n",
        "\n",
        "def train_preprocessing(x):\n",
        "    img = x\n",
        "    img = resize_and_rescale(img, size=(img_height, img_width))\n",
        "    img = augment(img)\n",
        "    return img\n",
        "\n",
        "train_ds = (\n",
        "    ds.map(train_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(batch_size, drop_remainder=True)\n",
        "    .shuffle(batch_size * 2)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2prJ11aVqtNR"
      },
      "outputs": [],
      "source": [
        "class GaussianDiffusion:\n",
        "  \"\"\"Gaussian diffusion utility.\n",
        "\n",
        "      beta_start is the start value of the scheduled variance\n",
        "      beta_end is the end value of the scheduled variance\n",
        "      timesteps is the number of time steps in the forward process\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      beta_start=1e-4,\n",
        "      beta_end=0.02,\n",
        "      timesteps=1000,\n",
        "      clip_min=-1.0,\n",
        "      clip_max=1.0,\n",
        "  ):\n",
        "      self.beta_start = beta_start\n",
        "      self.beta_end = beta_end\n",
        "      self.timesteps = timesteps\n",
        "      self.clip_min = clip_min\n",
        "      self.clip_max = clip_max\n",
        "\n",
        "      # Define the linear variance schedule\n",
        "      self.betas = betas = np.linspace(\n",
        "          beta_start,\n",
        "          beta_end,\n",
        "          timesteps,\n",
        "          dtype=np.float64,  # Using float64 for better precision\n",
        "      )\n",
        "      self.num_timesteps = int(timesteps)\n",
        "\n",
        "      alphas = 1.0 - betas\n",
        "      alphas_cumprod = np.cumprod(alphas, axis=0)\n",
        "      alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
        "\n",
        "      self.betas = tf.constant(betas, dtype=tf.float32)\n",
        "      self.alphas_cumprod = tf.constant(alphas_cumprod, dtype=tf.float32)\n",
        "      self.alphas_cumprod_prev = tf.constant(alphas_cumprod_prev, dtype=tf.float32)\n",
        "\n",
        "      # Calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "      self.sqrt_alphas_cumprod = tf.constant(\n",
        "          np.sqrt(alphas_cumprod), dtype=tf.float32\n",
        "      )\n",
        "\n",
        "      self.sqrt_one_minus_alphas_cumprod = tf.constant(\n",
        "          np.sqrt(1.0 - alphas_cumprod), dtype=tf.float32\n",
        "      )\n",
        "\n",
        "      self.log_one_minus_alphas_cumprod = tf.constant(\n",
        "          np.log(1.0 - alphas_cumprod), dtype=tf.float32\n",
        "      )\n",
        "\n",
        "      self.sqrt_recip_alphas_cumprod = tf.constant(\n",
        "          np.sqrt(1.0 / alphas_cumprod), dtype=tf.float32\n",
        "      )\n",
        "      self.sqrt_recipm1_alphas_cumprod = tf.constant(\n",
        "          np.sqrt(1.0 / alphas_cumprod - 1), dtype=tf.float32\n",
        "      )\n",
        "\n",
        "      # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "      posterior_variance = (\n",
        "          betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "      )\n",
        "      self.posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
        "\n",
        "      # Log calculation clipped because the posterior variance is 0 at the beginning\n",
        "      # of the diffusion chain\n",
        "      self.posterior_log_variance_clipped = tf.constant(\n",
        "          np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32\n",
        "      )\n",
        "\n",
        "      self.posterior_mean_coef1 = tf.constant(\n",
        "          betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod),\n",
        "          dtype=tf.float32,\n",
        "      )\n",
        "\n",
        "      self.posterior_mean_coef2 = tf.constant(\n",
        "          (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod),\n",
        "          dtype=tf.float32,\n",
        "      )\n",
        "\n",
        "  def _extract(self, a, t, x_shape):\n",
        "      \"\"\"Extract some coefficients at specified timesteps,\n",
        "      then reshape to [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.\n",
        "\n",
        "      Args:\n",
        "          a: Tensor to extract from\n",
        "          t: Timestep for which the coefficients are to be extracted\n",
        "          x_shape: Shape of the current batched samples\n",
        "      \"\"\"\n",
        "      batch_size = x_shape[0]\n",
        "      out = tf.gather(a, t)\n",
        "      return tf.reshape(out, [batch_size, 1, 1, 1])\n",
        "\n",
        "  def q_mean_variance(self, x_start, t):\n",
        "      \"\"\"Extracts the mean, and the variance at current timestep.\n",
        "\n",
        "      Args:\n",
        "          x_start: Initial sample (before the first diffusion step)\n",
        "          t: Current timestep\n",
        "      \"\"\"\n",
        "      x_start_shape = tf.shape(x_start)\n",
        "      mean = self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
        "      variance = self._extract(1.0 - self.alphas_cumprod, t, x_start_shape)\n",
        "      log_variance = self._extract(\n",
        "          self.log_one_minus_alphas_cumprod, t, x_start_shape\n",
        "      )\n",
        "      return mean, variance, log_variance\n",
        "\n",
        "  def q_sample(self, x_start, t, noise):\n",
        "      \"\"\"Diffuse the data.\n",
        "\n",
        "      Args:\n",
        "          x_start: Initial sample (before the first diffusion step)\n",
        "          t: Current timestep\n",
        "          noise: Gaussian noise to be added at the current timestep\n",
        "      Returns:\n",
        "          Diffused samples at timestep `t`\n",
        "      \"\"\"\n",
        "      x_start_shape = tf.shape(x_start)\n",
        "      return (\n",
        "          self._extract(self.sqrt_alphas_cumprod, t, tf.shape(x_start)) * x_start\n",
        "          + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape)\n",
        "          * noise\n",
        "      )\n",
        "\n",
        "  def predict_start_from_noise(self, x_t, t, noise):\n",
        "      x_t_shape = tf.shape(x_t)\n",
        "      return (\n",
        "          self._extract(self.sqrt_recip_alphas_cumprod, t, x_t_shape) * x_t\n",
        "          - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t_shape) * noise\n",
        "      )\n",
        "\n",
        "  def q_posterior(self, x_start, x_t, t):\n",
        "      \"\"\"Compute the mean and variance of the diffusion\n",
        "      posterior q(x_{t-1} | x_t, x_0).\n",
        "\n",
        "      Args:\n",
        "          x_start: Stating point(sample) for the posterior computation\n",
        "          x_t: Sample at timestep `t`\n",
        "          t: Current timestep\n",
        "      Returns:\n",
        "          Posterior mean and variance at current timestep\n",
        "      \"\"\"\n",
        "\n",
        "      x_t_shape = tf.shape(x_t)\n",
        "      posterior_mean = (\n",
        "          self._extract(self.posterior_mean_coef1, t, x_t_shape) * x_start\n",
        "          + self._extract(self.posterior_mean_coef2, t, x_t_shape) * x_t\n",
        "      )\n",
        "      posterior_variance = self._extract(self.posterior_variance, t, x_t_shape)\n",
        "      posterior_log_variance_clipped = self._extract(\n",
        "          self.posterior_log_variance_clipped, t, x_t_shape\n",
        "      )\n",
        "      return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
        "\n",
        "  def p_mean_variance(self, pred_noise, x, t, clip_denoised=True):\n",
        "      x_recon = self.predict_start_from_noise(x, t=t, noise=pred_noise)\n",
        "      if clip_denoised:\n",
        "          x_recon = tf.clip_by_value(x_recon, self.clip_min, self.clip_max)\n",
        "\n",
        "      model_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n",
        "          x_start=x_recon, x_t=x, t=t\n",
        "      )\n",
        "      return model_mean, posterior_variance, posterior_log_variance\n",
        "\n",
        "  def p_sample(self, pred_noise, x, t, clip_denoised=True):\n",
        "      \"\"\"Sample from the diffusion model.\n",
        "\n",
        "      Args:\n",
        "          pred_noise: Noise predicted by the diffusion model\n",
        "          x: Samples at a given timestep for which the noise was predicted\n",
        "          t: Current timestep\n",
        "          clip_denoised (bool): Whether to clip the predicted noise\n",
        "              within the specified range or not.\n",
        "      \"\"\"\n",
        "      model_mean, _, model_log_variance = self.p_mean_variance(\n",
        "          pred_noise, x=x, t=t, clip_denoised=clip_denoised\n",
        "      )\n",
        "      noise = tf.random.normal(shape=x.shape, dtype=x.dtype)\n",
        "      # No noise when t == 0\n",
        "      nonzero_mask = tf.reshape(\n",
        "          1 - tf.cast(tf.equal(t, 0), tf.float32), [tf.shape(x)[0], 1, 1, 1]\n",
        "      )\n",
        "      return model_mean + nonzero_mask * tf.exp(0.5 * model_log_variance) * noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpuQW3cbUKrV"
      },
      "outputs": [],
      "source": [
        "#Kernel initialiser for the U-Net architecture\n",
        "def kernel_init(scale):\n",
        "  scale = max(scale, 1e-10)\n",
        "  return keras.initializers.VarianceScaling(\n",
        "      scale, mode=\"fan_avg\", distribution=\"uniform\"\n",
        "  )\n",
        "\n",
        "\"\"\"Applying self-attention.\n",
        "\n",
        "units is the number of units un the dense layer\n",
        "groups is the number of groups to be used for GroupNormalization layer\n",
        "\"\"\"\n",
        "class AttentionBlock(layers.Layer):\n",
        "    \"\"\"Applies self-attention.\n",
        "\n",
        "    Args:\n",
        "        units: Number of units in the dense layers\n",
        "        groups: Number of groups to be used for GroupNormalization layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units, groups=8, **kwargs):\n",
        "        self.units = units\n",
        "        self.groups = groups\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.norm = layers.GroupNormalization(groups=groups)\n",
        "        self.query = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
        "        self.key = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
        "        self.value = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
        "        self.proj = layers.Dense(units, kernel_initializer=kernel_init(0.0))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        height = tf.shape(inputs)[1]\n",
        "        width = tf.shape(inputs)[2]\n",
        "        scale = tf.cast(self.units, tf.float32) ** (-0.5)\n",
        "\n",
        "        inputs = self.norm(inputs)\n",
        "        q = self.query(inputs)\n",
        "        k = self.key(inputs)\n",
        "        v = self.value(inputs)\n",
        "\n",
        "        attn_score = tf.einsum(\"bhwc, bHWc->bhwHW\", q, k) * scale\n",
        "        attn_score = tf.reshape(attn_score, [batch_size, height, width, height * width])\n",
        "\n",
        "        attn_score = tf.nn.softmax(attn_score, -1)\n",
        "        attn_score = tf.reshape(attn_score, [batch_size, height, width, height, width])\n",
        "\n",
        "        proj = tf.einsum(\"bhwHW,bHWc->bhwc\", attn_score, v)\n",
        "        proj = self.proj(proj)\n",
        "        return inputs + proj\n",
        "\n",
        "class TimeEmbedding(layers.Layer):\n",
        "  def __init__(self, dim, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.dim = dim\n",
        "    self.half_dim = dim // 2\n",
        "    self.emb = math.log(10000) / (self.half_dim - 1)\n",
        "    self.emb = tf.exp(tf.range(self.half_dim, dtype=tf.float32) * -self.emb)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    inputs = tf.cast(inputs, dtype=tf.float32)\n",
        "    emb = inputs[:, None] * self.emb[None, :]\n",
        "    emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
        "    return emb\n",
        "\n",
        "def ResidualBlock(width, groups=8, activation_fn=keras.activations.swish):\n",
        "  def apply(inputs):\n",
        "    x, t = inputs\n",
        "    input_width = x.shape[3]\n",
        "\n",
        "    if input_width == width:\n",
        "      residual = x\n",
        "    else:\n",
        "      residual = layers.Conv2D(\n",
        "          width, kernel_size=1, kernel_initializer=kernel_init(1.0)\n",
        "      )(x)\n",
        "\n",
        "    temb = activation_fn(t)\n",
        "    temb = layers.Dense(width, kernel_initializer=kernel_init(1.0))(temb)[\n",
        "        :, None, None, :\n",
        "    ]\n",
        "\n",
        "    x = layers.GroupNormalization(groups=groups)(x)\n",
        "    x = activation_fn(x)\n",
        "    x = layers.Conv2D(\n",
        "        width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(1.0)\n",
        "    )(x)\n",
        "\n",
        "    x = layers.Add()([x, temb])\n",
        "    x = layers.GroupNormalization(groups=groups)(x)\n",
        "    x = activation_fn(x)\n",
        "\n",
        "    x = layers.Conv2D(\n",
        "        width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(0.0)\n",
        "    )(x)\n",
        "    x = layers.Add()([x, residual])\n",
        "    return x\n",
        "\n",
        "  return apply\n",
        "\n",
        "def DownSample(width):\n",
        "  def apply(x):\n",
        "    x = layers.Conv2D(\n",
        "        width,\n",
        "        kernel_size=3,\n",
        "        strides=2,\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=kernel_init(1.0),\n",
        "    )(x)\n",
        "    return x\n",
        "\n",
        "  return apply\n",
        "\n",
        "def UpSample(width, interpolation=\"nearest\"):\n",
        "  def apply(x):\n",
        "    x = layers.UpSampling2D(size=2, interpolation=interpolation)(x)\n",
        "    x = layers.Conv2D(\n",
        "        width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(1.0)\n",
        "    )(x)\n",
        "    return x\n",
        "\n",
        "  return apply\n",
        "\n",
        "def TimeMLP(units, activation_fn=keras.activations.swish):\n",
        "  def apply(inputs):\n",
        "    temb = layers.Dense(\n",
        "        units, activation=activation_fn, kernel_initializer=kernel_init(1.0)\n",
        "    )(inputs)\n",
        "    temb = layers.Dense(units, kernel_initializer=kernel_init(1.0))(temb)\n",
        "    return temb\n",
        "\n",
        "  return apply\n",
        "\n",
        "def build_model(\n",
        "    img_height,\n",
        "    img_width,\n",
        "    img_channels,\n",
        "    widths,\n",
        "    has_attention,\n",
        "    num_res_blocks=2,\n",
        "    norm_groups=32,\n",
        "    interpolation=\"nearest\",\n",
        "    activation_fn=keras.activations.swish,\n",
        "):\n",
        "  image_input = layers.Input(\n",
        "      shape=(img_height, img_width, img_channels), name=\"image_input\"\n",
        "  )\n",
        "  time_input = keras.Input(shape=(), dtype=tf.int64, name=\"time_input\")\n",
        "\n",
        "  x = layers.Conv2D(\n",
        "      first_conv_channels,\n",
        "      kernel_size=(3, 3),\n",
        "      padding=\"same\",\n",
        "      kernel_initializer=kernel_init(1.0),\n",
        "  )(image_input)\n",
        "\n",
        "  temb = TimeEmbedding(dim=first_conv_channels * 4)(time_input)\n",
        "  temb = TimeMLP(units=first_conv_channels * 4, activation_fn=activation_fn)(temb)\n",
        "\n",
        "  skips = [x]\n",
        "\n",
        "  #Downblock\n",
        "  for i in range(len(widths)):\n",
        "    for _ in range(num_res_blocks):\n",
        "      x = ResidualBlock(\n",
        "          widths[i], groups=norm_groups, activation_fn=activation_fn\n",
        "      )([x, temb])\n",
        "      if has_attention[i]:\n",
        "        x = AttentionBlock(widths[i], groups=norm_groups)(x)\n",
        "      skips.append(x)\n",
        "\n",
        "    if widths[i] != widths[-1]:\n",
        "      x = DownSample(widths[i])(x)\n",
        "      skips.append(x)\n",
        "\n",
        "  #Middleblock\n",
        "  x = ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)(\n",
        "      [x, temb]\n",
        "  )\n",
        "  x = AttentionBlock(widths[-1], groups=norm_groups)(x)\n",
        "  x = ResidualBlock(widths[-1], groups = norm_groups, activation_fn=activation_fn)(\n",
        "      [x, temb]\n",
        "  )\n",
        "\n",
        "  #Upblock\n",
        "  for i in reversed(range(len(widths))):\n",
        "    for _ in range(num_res_blocks + 1):\n",
        "      x = layers.Concatenate(axis=-1)([x, skips.pop()])\n",
        "      x = ResidualBlock(\n",
        "          widths[i], groups=norm_groups, activation_fn=activation_fn\n",
        "      )([x, temb])\n",
        "      if has_attention[i]:\n",
        "        x = AttentionBlock(widths[i], groups=norm_groups)(x)\n",
        "\n",
        "    if i != 0:\n",
        "      x = UpSample(widths[i], interpolation=interpolation)(x)\n",
        "\n",
        "  #Endblock\n",
        "  x = layers.GroupNormalization(groups=norm_groups)(x)\n",
        "  x = activation_fn(x)\n",
        "  x = layers.Conv2D(3, (3, 3), padding=\"same\", kernel_initializer=kernel_init(0.0))(x)\n",
        "  return keras.Model([image_input, time_input], x, name=\"unet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6Oa0MpcgPlF"
      },
      "outputs": [],
      "source": [
        "class DiffusionModel(keras.Model):\n",
        "  def __init__(self, network, ema_network, timesteps, gdf_util, ema=0.999):\n",
        "    super().__init__()\n",
        "    self.network = network\n",
        "    self.ema_network = ema_network\n",
        "    self.timesteps = timesteps\n",
        "    self.gdf_util = gdf_util\n",
        "    self.ema = ema\n",
        "\n",
        "  def train_step(self, images):\n",
        "    #First we get the btach size\n",
        "    batch_size = tf.shape(images)[0]\n",
        "\n",
        "    #Then we sample timesteps uniformly\n",
        "    t = tf.random.uniform(\n",
        "        minval=0, maxval=self.timesteps, shape=(batch_size,), dtype=tf.int64\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      #We sample the random noise to be added to the images in the batch\n",
        "      noise = tf.random.normal(shape=tf.shape(images), dtype=images.dtype)\n",
        "\n",
        "      #We diffuse the images with noise\n",
        "      images_t = self.gdf_util.q_sample(images, t, noise)\n",
        "\n",
        "      #Pass the diffused images and time steps to the network\n",
        "      pred_noise = self.network([images_t, t], training=True)\n",
        "\n",
        "      #Calculate the loss\n",
        "      loss = self.loss(noise, pred_noise)\n",
        "\n",
        "    #Get the gradients\n",
        "    gradients = tape.gradient(loss, self.network.trainable_weights)\n",
        "\n",
        "    #Update the weights of the network\n",
        "    self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n",
        "\n",
        "    #Update the weight values for the network with EMA weight\n",
        "    for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
        "      ema_weight.assign(self.ema * ema_weight + (1 - self.ema) * weight)\n",
        "\n",
        "    #Return loss values\n",
        "    return {\"loss\": loss}\n",
        "\n",
        "  def generate_images(self, num_images=16):\n",
        "    #First we randomly sample noise\n",
        "    samples = tf.random.normal(\n",
        "        shape=(num_images, img_height, img_width, img_channels), dtype=tf.float32\n",
        "    )\n",
        "\n",
        "    #Sample from the model iteratively\n",
        "    for t in reversed(range(0, self.timesteps)):\n",
        "      tt = tf.cast(tf.fill(num_images, t), dtype=tf.int64)\n",
        "      pred_noise = self.ema_network.predict(\n",
        "          [samples, tt], verbose=0, batch_size=num_images\n",
        "      )\n",
        "      samples = self.gdf_util.p_sample(\n",
        "          pred_noise, samples, tt, clip_denoised=True\n",
        "      )\n",
        "\n",
        "      #Return generated samples\n",
        "    return samples\n",
        "\n",
        "  def plot_images(self, epoch=None, logs=None, num_rows=2, num_cols=4, figsize=(12,5)):\n",
        "    generated_samples = self.generate_images(num_images=num_rows * num_cols)\n",
        "    generated_samples = (\n",
        "        tf.clip_by_value(generated_samples * 127.5 + 127.5, 0.0, 255.0)\n",
        "        .numpy()\n",
        "        .astype(np.uint8)\n",
        "    )\n",
        "\n",
        "    _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
        "    for i, image in enumerate(generated_samples):\n",
        "      if num_rows == 1:\n",
        "        ax[i].imshow(image)\n",
        "        ax[i].axis(\"off\")\n",
        "      else:\n",
        "        ax[i // num_cols, i % num_cols].imshow(image)\n",
        "        ax[i // num_cols, i % num_cols].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/1.MelodiaAtomizacji/SenaTrainings/23.08.24 - Training 2/training_%03d.png' % (epoch+1))\n",
        "    plt.close()\n",
        "\n",
        "checkWeights = tf.keras.callbacks.ModelCheckpoint(\n",
        "  filepath='/content/drive/MyDrive/1.MelodiaAtomizacji/SenaTrainings/23.08.24 - Training 2/model_cp/senaDiff.ckpt',\n",
        "  save_weights_only=True,\n",
        "  verbose=1\n",
        ")\n",
        "\n",
        "#Build the UNet model\n",
        "network = build_model(\n",
        "  img_height=img_height,\n",
        "  img_width=img_width,\n",
        "  img_channels=img_channels,\n",
        "  widths=widths,\n",
        "  has_attention=has_attention,\n",
        "  num_res_blocks=num_res_blocks,\n",
        "  norm_groups=norm_groups,\n",
        "  activation_fn=keras.activations.swish,\n",
        ")\n",
        "ema_network = build_model(\n",
        "  img_height=img_height,\n",
        "  img_width=img_width,\n",
        "  img_channels=img_channels,\n",
        "  widths=widths,\n",
        "  has_attention=has_attention,\n",
        "  num_res_blocks=num_res_blocks,\n",
        "  norm_groups=norm_groups,\n",
        "  activation_fn=keras.activations.swish,\n",
        ")\n",
        "ema_network.set_weights(network.get_weights())\n",
        "\n",
        "#Get an instance of the gaussian diffusion\n",
        "gdf_util = GaussianDiffusion(timesteps=total_timesteps)\n",
        "\n",
        "#Get the model\n",
        "model = DiffusionModel(\n",
        "  network=network,\n",
        "  ema_network=ema_network,\n",
        "  gdf_util=gdf_util,\n",
        "  timesteps=total_timesteps,\n",
        ")\n",
        "\n",
        "#Compile the model\n",
        "model.compile(\n",
        "  loss=keras.losses.MeanSquaredError(),\n",
        "  optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading previously trained-weights\n",
        "model.load_weights('/content/drive/MyDrive/1.MelodiaAtomizacji/SenaTrainings/23.08.24 - Training 2/model_cp/senaDiff.ckpt')"
      ],
      "metadata": {
        "id": "u3Lqf5gR2Dps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvjooD4ae1Ie"
      },
      "outputs": [],
      "source": [
        "#Train the model\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  epochs=num_epochs,\n",
        "  batch_size=batch_size,\n",
        "  callbacks=[\n",
        "      keras.callbacks.LambdaCallback(on_epoch_end=model.plot_images), #to plot and save training epoch results\n",
        "      save_weights, #to checkpoint the weights\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the model weights\n",
        "tf.keras.callbacks.ModelCheckpoint(\n",
        "  filepath='/content/drive/MyDrive/1.MelodiaAtomizacji/SenaTrainings/23.08.24 - Training 2/model_cp/senaDiff.ckpt',\n",
        "  save_weights_only=True,\n",
        "  verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "U4-Pp3Bll_8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#Then we plot images\n",
        "model.plot_images(num_rows=2, num_cols=2)\"\"\"\n",
        "\n",
        "#Plotting the images\n"
      ],
      "metadata": {
        "id": "wTdxU1Co6E2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNzNgJnXmXE9b7xJ00TNC+2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}